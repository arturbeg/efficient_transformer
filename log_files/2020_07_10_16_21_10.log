INFO:root:./model_files/2020_07_10_16_21_10.pt
INFO:root:The batch size is: 64
INFO:root:Number of epochs is : 2
INFO:root:The context length is : 128
INFO:root:D_model is : 256
INFO:root:Number of attention heads is : 4
INFO:root:Number of decoder layers is : 3
INFO:root:Initial learning rate is : 1.0
INFO:root:Number of warmup steps is : 4000
INFO:root:k is : 2
INFO:root:Number of experts is : 128
INFO:root:Type of gating used : FNN gating
WARNING:absl:TFDS datasets with text encoding are deprecated and will be removed in a future version. Instead, you should use the plain text version and tokenize the text using `tensorflow_text` (See: https://www.tensorflow.org/tutorials/tensorflow_text/intro#tfdata_example)
INFO:absl:Load dataset info from ./subwords32k/lm1b/subwords32k/1.0.0
INFO:absl:Reusing dataset lm1b (./subwords32k/lm1b/subwords32k/1.0.0)
INFO:absl:Constructing tf.data.Dataset for split train, from ./subwords32k/lm1b/subwords32k/1.0.0
WARNING:absl:TFDS datasets with text encoding are deprecated and will be removed in a future version. Instead, you should use the plain text version and tokenize the text using `tensorflow_text` (See: https://www.tensorflow.org/tutorials/tensorflow_text/intro#tfdata_example)
INFO:absl:Load dataset info from ./subwords32k/lm1b/subwords32k/1.0.0
INFO:absl:Reusing dataset lm1b (./subwords32k/lm1b/subwords32k/1.0.0)
INFO:absl:Constructing tf.data.Dataset for split test, from ./subwords32k/lm1b/subwords32k/1.0.0
INFO:root:Gating function is: none
INFO:root:The optimizer used is: adam
INFO:root:Current Epoch is: 1
INFO:root:Running without errors
INFO:root:Learning rate has changed to: 3.186982954388445e-05
INFO:root:| epoch   1 | batch   128 | ms/batch 13284.57 | loss    10.5806 | aux_loss     0.9839 | ppl 39362.4542
INFO:root:Learning rate has changed to: 6.349260614556825e-05
INFO:root:| epoch   1 | batch   256 | ms/batch 13063.81 | loss     9.9926 | aux_loss     0.9777 | ppl 21864.0939
INFO:root:Learning rate has changed to: 9.511538274725204e-05
INFO:root:| epoch   1 | batch   384 | ms/batch 13083.31 | loss     8.0637 | aux_loss     0.9781 | ppl  3176.9607
INFO:root:Learning rate has changed to: 0.00012673815934893584
INFO:root:| epoch   1 | batch   512 | ms/batch 13084.92 | loss     7.3521 | aux_loss     0.9761 | ppl  1559.3992
INFO:root:Learning rate has changed to: 0.00015836093595061963
INFO:root:| epoch   1 | batch   640 | ms/batch 13092.91 | loss     7.1598 | aux_loss     0.9759 | ppl  1286.6610
INFO:root:Learning rate has changed to: 0.00018998371255230342
INFO:root:| epoch   1 | batch   768 | ms/batch 13122.37 | loss     6.9927 | aux_loss     0.9763 | ppl  1088.6538
INFO:root:Learning rate has changed to: 0.00022160648915398723
INFO:root:| epoch   1 | batch   896 | ms/batch 13201.75 | loss     6.8653 | aux_loss     0.9736 | ppl   958.4212
INFO:root:Learning rate has changed to: 0.000253229265755671
INFO:root:| epoch   1 | batch  1024 | ms/batch 13146.31 | loss     6.7474 | aux_loss     0.9748 | ppl   851.8007
INFO:root:Learning rate has changed to: 0.0002848520423573548
INFO:root:| epoch   1 | batch  1152 | ms/batch 13155.41 | loss     6.6288 | aux_loss     0.9755 | ppl   756.5529
INFO:root:Learning rate has changed to: 0.0003164748189590386
INFO:root:| epoch   1 | batch  1280 | ms/batch 13211.23 | loss     6.5440 | aux_loss     0.9756 | ppl   695.0407
INFO:root:Learning rate has changed to: 0.0003480975955607224
INFO:root:| epoch   1 | batch  1408 | ms/batch 13154.51 | loss     6.4615 | aux_loss     0.9753 | ppl   639.9902
INFO:root:Learning rate has changed to: 0.0003797203721624062
INFO:root:| epoch   1 | batch  1536 | ms/batch 13216.49 | loss     6.3887 | aux_loss     0.9757 | ppl   595.0744
INFO:root:Learning rate has changed to: 0.00041134314876409
INFO:root:| epoch   1 | batch  1664 | ms/batch 13168.12 | loss     6.3204 | aux_loss     0.9768 | ppl   555.7831
INFO:root:Learning rate has changed to: 0.0004429659253657738
INFO:root:| epoch   1 | batch  1792 | ms/batch 13237.19 | loss     6.2515 | aux_loss     0.9754 | ppl   518.7814
INFO:root:Learning rate has changed to: 0.0004745887019674576
INFO:root:| epoch   1 | batch  1920 | ms/batch 13193.87 | loss     6.1879 | aux_loss     0.9763 | ppl   486.8296
INFO:root:Learning rate has changed to: 0.0005062114785691414
INFO:root:| epoch   1 | batch  2048 | ms/batch 13155.51 | loss     6.1479 | aux_loss     0.9757 | ppl   467.7158
INFO:root:Learning rate has changed to: 0.0005378342551708252
INFO:root:| epoch   1 | batch  2176 | ms/batch 13177.84 | loss     6.0875 | aux_loss     0.9759 | ppl   440.3113
INFO:root:Learning rate has changed to: 0.000569457031772509
INFO:root:| epoch   1 | batch  2304 | ms/batch 13145.67 | loss     6.0376 | aux_loss     0.9755 | ppl   418.8919
INFO:root:Learning rate has changed to: 0.0006010798083741928
INFO:root:| epoch   1 | batch  2432 | ms/batch 13209.57 | loss     5.9853 | aux_loss     0.9750 | ppl   397.5238
INFO:root:Learning rate has changed to: 0.0006327025849758765
INFO:root:| epoch   1 | batch  2560 | ms/batch 13190.36 | loss     5.9544 | aux_loss     0.9767 | ppl   385.4541
INFO:root:Learning rate has changed to: 0.0006643253615775603
INFO:root:| epoch   1 | batch  2688 | ms/batch 13167.45 | loss     5.9131 | aux_loss     0.9733 | ppl   369.8645
INFO:root:Learning rate has changed to: 0.0006959481381792441
INFO:root:| epoch   1 | batch  2816 | ms/batch 13198.06 | loss     5.8847 | aux_loss     0.9754 | ppl   359.4777
INFO:root:Learning rate has changed to: 0.000727570914780928
INFO:root:| epoch   1 | batch  2944 | ms/batch 13172.43 | loss     5.8530 | aux_loss     0.9743 | ppl   348.2932
INFO:root:Learning rate has changed to: 0.0007591936913826118
INFO:root:| epoch   1 | batch  3072 | ms/batch 13123.87 | loss     5.8141 | aux_loss     0.9751 | ppl   335.0028
INFO:root:Learning rate has changed to: 0.0007908164679842956
INFO:root:| epoch   1 | batch  3200 | ms/batch 13091.40 | loss     5.7834 | aux_loss     0.9736 | ppl   324.8681
INFO:root:Learning rate has changed to: 0.0008224392445859793
INFO:root:| epoch   1 | batch  3328 | ms/batch 12678.71 | loss     5.7608 | aux_loss     0.9735 | ppl   317.6002
INFO:root:Learning rate has changed to: 0.0008540620211876631
INFO:root:| epoch   1 | batch  3456 | ms/batch 12638.55 | loss     5.7379 | aux_loss     0.9739 | ppl   310.4082
INFO:root:Learning rate has changed to: 0.0008856847977893469
INFO:root:| epoch   1 | batch  3584 | ms/batch 12549.19 | loss     5.7178 | aux_loss     0.9728 | ppl   304.2274
INFO:root:Learning rate has changed to: 0.0009173075743910307
INFO:root:| epoch   1 | batch  3712 | ms/batch 12455.48 | loss     5.6967 | aux_loss     0.9730 | ppl   297.8814
INFO:root:Learning rate has changed to: 0.0009489303509927146
INFO:root:| epoch   1 | batch  3840 | ms/batch 12497.75 | loss     5.6623 | aux_loss     0.9727 | ppl   287.8193
INFO:root:Learning rate has changed to: 0.0009805531275943983
INFO:root:| epoch   1 | batch  3968 | ms/batch 12542.58 | loss     5.6490 | aux_loss     0.9743 | ppl   284.0144
INFO:root:Learning rate has changed to: 0.0009764433125338821
INFO:root:| epoch   1 | batch  4096 | ms/batch 12537.24 | loss     5.6359 | aux_loss     0.9708 | ppl   280.3020
INFO:root:Learning rate has changed to: 0.0009615384615384616
INFO:root:| epoch   1 | batch  4224 | ms/batch 12544.68 | loss     5.6187 | aux_loss     0.9706 | ppl   275.5172
INFO:root:Learning rate has changed to: 0.0009472959569955596
INFO:root:| epoch   1 | batch  4352 | ms/batch 12721.64 | loss     5.5928 | aux_loss     0.9712 | ppl   268.4776
INFO:root:Learning rate has changed to: 0.0009336681528218903
INFO:root:| epoch   1 | batch  4480 | ms/batch 12718.05 | loss     5.5704 | aux_loss     0.9688 | ppl   262.5465
INFO:root:Learning rate has changed to: 0.0009206120672864873
INFO:root:| epoch   1 | batch  4608 | ms/batch 12843.83 | loss     5.5566 | aux_loss     0.9672 | ppl   258.9394
INFO:root:Learning rate has changed to: 0.0009080888118835636
INFO:root:| epoch   1 | batch  4736 | ms/batch 12877.17 | loss     5.5365 | aux_loss     0.9678 | ppl   253.7920
INFO:root:Learning rate has changed to: 0.0008960631034158175
INFO:root:| epoch   1 | batch  4864 | ms/batch 12716.25 | loss     5.5179 | aux_loss     0.9670 | ppl   249.1130
INFO:root:Learning rate has changed to: 0.0008845028453299376
INFO:root:| epoch   1 | batch  4992 | ms/batch 12689.87 | loss     5.5005 | aux_loss     0.9674 | ppl   244.8147
INFO:root:Learning rate has changed to: 0.0008733787669798303
INFO:root:| epoch   1 | batch  5120 | ms/batch 12282.47 | loss     5.4920 | aux_loss     0.9644 | ppl   242.7497
INFO:root:Learning rate has changed to: 0.0008626641115774413
INFO:root:| epoch   1 | batch  5248 | ms/batch 11944.82 | loss     5.4828 | aux_loss     0.9658 | ppl   240.5309
INFO:root:Learning rate has changed to: 0.000852334365251007
INFO:root:| epoch   1 | batch  5376 | ms/batch 12642.50 | loss     5.4671 | aux_loss     0.9649 | ppl   236.7822
INFO:root:Learning rate has changed to: 0.0008423670209604698
INFO:root:| epoch   1 | batch  5504 | ms/batch 12515.57 | loss     5.4506 | aux_loss     0.9638 | ppl   232.9035
INFO:root:Learning rate has changed to: 0.0008327413720912831
INFO:root:| epoch   1 | batch  5632 | ms/batch 12647.43 | loss     5.4391 | aux_loss     0.9643 | ppl   230.2393
INFO:root:Learning rate has changed to: 0.00082343833141581
INFO:root:| epoch   1 | batch  5760 | ms/batch 12536.63 | loss     5.4423 | aux_loss     0.9627 | ppl   230.9649
INFO:root:Learning rate has changed to: 0.0008144402718182064
INFO:root:| epoch   1 | batch  5888 | ms/batch 12643.65 | loss     5.4169 | aux_loss     0.9624 | ppl   225.1748
INFO:root:Learning rate has changed to: 0.0008057308857568942
INFO:root:| epoch   1 | batch  6016 | ms/batch 12722.09 | loss     5.4002 | aux_loss     0.9630 | ppl   221.4531
INFO:root:Learning rate has changed to: 0.0007972950609139956
INFO:root:| epoch   1 | batch  6144 | ms/batch 12665.77 | loss     5.4000 | aux_loss     0.9628 | ppl   221.4016
INFO:root:Learning rate has changed to: 0.0007891187698735106
INFO:root:| epoch   1 | batch  6272 | ms/batch 12691.41 | loss     5.3840 | aux_loss     0.9623 | ppl   217.8996
INFO:root:Learning rate has changed to: 0.0007811889719953762
INFO:root:| epoch   1 | batch  6400 | ms/batch 12731.02 | loss     5.3863 | aux_loss     0.9626 | ppl   218.3890
INFO:root:Learning rate has changed to: 0.0007734935259234094
INFO:root:| epoch   1 | batch  6528 | ms/batch 12711.36 | loss     5.3712 | aux_loss     0.9617 | ppl   215.1203
INFO:root:Learning rate has changed to: 0.0007660211113915147
INFO:root:| epoch   1 | batch  6656 | ms/batch 12714.19 | loss     5.3593 | aux_loss     0.9606 | ppl   212.5775
INFO:root:Learning rate has changed to: 0.0007587611591824277
INFO:root:| epoch   1 | batch  6784 | ms/batch 12688.59 | loss     5.3537 | aux_loss     0.9599 | ppl   211.3946
INFO:root:Learning rate has changed to: 0.0007517037882531398
INFO:root:| epoch   1 | batch  6912 | ms/batch 12702.10 | loss     5.3443 | aux_loss     0.9618 | ppl   209.4204
INFO:root:Learning rate has changed to: 0.0007448397491761886
INFO:root:| epoch   1 | batch  7040 | ms/batch 12742.55 | loss     5.3348 | aux_loss     0.9601 | ppl   207.4240
INFO:root:Learning rate has changed to: 0.000738160373160463
INFO:root:| epoch   1 | batch  7168 | ms/batch 12718.41 | loss     5.3297 | aux_loss     0.9606 | ppl   206.3749
INFO:root:Learning rate has changed to: 0.0007316575260124783
INFO:root:| epoch   1 | batch  7296 | ms/batch 12678.19 | loss     5.3221 | aux_loss     0.9595 | ppl   204.8195
INFO:root:Learning rate has changed to: 0.0007253235664820743
INFO:root:| epoch   1 | batch  7424 | ms/batch 11560.87 | loss     5.3073 | aux_loss     0.9605 | ppl   201.8030
INFO:root:Learning rate has changed to: 0.0007191513085074671
INFO:root:| epoch   1 | batch  7552 | ms/batch 11487.33 | loss     5.3034 | aux_loss     0.9587 | ppl   201.0174
INFO:root:Learning rate has changed to: 0.0007131339869354735
INFO:root:| epoch   1 | batch  7680 | ms/batch 12053.15 | loss     5.2967 | aux_loss     0.9604 | ppl   199.6672
INFO:root:Learning rate has changed to: 0.0007072652263450946
INFO:root:| epoch   1 | batch  7808 | ms/batch 11659.95 | loss     5.2913 | aux_loss     0.9589 | ppl   198.5995
INFO:root:Learning rate has changed to: 0.0007015390126478009
INFO:root:| epoch   1 | batch  7936 | ms/batch 11621.97 | loss     5.2855 | aux_loss     0.9588 | ppl   197.4473
INFO:root:Learning rate has changed to: 0.0006959496671769054
INFO:root:| epoch   1 | batch  8064 | ms/batch 11519.65 | loss     5.2814 | aux_loss     0.9588 | ppl   196.6531
