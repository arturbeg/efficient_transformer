WARNING: You have a CUDA device, so you should probably run with --cuda
Gating function is:  moe
Running without errors
| epoch   1 |   200/ 2983 batches | lr 0.20 | ms/batch 1134.69 | loss  8.41 | ppl  4469.98
| epoch   1 |   400/ 2983 batches | lr 0.20 | ms/batch 1115.20 | loss  7.18 | ppl  1307.09
| epoch   1 |   600/ 2983 batches | lr 0.20 | ms/batch 1121.22 | loss  6.84 | ppl   938.37
| epoch   1 |   800/ 2983 batches | lr 0.20 | ms/batch 1123.72 | loss  6.75 | ppl   852.34
| epoch   1 |  1000/ 2983 batches | lr 0.20 | ms/batch 1121.00 | loss  6.67 | ppl   789.44
| epoch   1 |  1200/ 2983 batches | lr 0.20 | ms/batch 1129.26 | loss  6.66 | ppl   782.21
| epoch   1 |  1400/ 2983 batches | lr 0.20 | ms/batch 1118.25 | loss  6.60 | ppl   733.22
| epoch   1 |  1600/ 2983 batches | lr 0.20 | ms/batch 1121.22 | loss  6.63 | ppl   754.05
| epoch   1 |  1800/ 2983 batches | lr 0.20 | ms/batch 1138.84 | loss  6.53 | ppl   684.21
| epoch   1 |  2000/ 2983 batches | lr 0.20 | ms/batch 1124.07 | loss  6.54 | ppl   690.82
| epoch   1 |  2200/ 2983 batches | lr 0.20 | ms/batch 1118.64 | loss  6.48 | ppl   653.23
| epoch   1 |  2400/ 2983 batches | lr 0.20 | ms/batch 1131.08 | loss  6.47 | ppl   643.23
| epoch   1 |  2600/ 2983 batches | lr 0.20 | ms/batch 1121.93 | loss  6.48 | ppl   651.21
| epoch   1 |  2800/ 2983 batches | lr 0.20 | ms/batch 1142.86 | loss  6.42 | ppl   616.43
-----------------------------------------------------------------------------------------
| end of epoch   1 | time: 3470.83s | valid loss  2.60 | valid ppl    13.45
-----------------------------------------------------------------------------------------
Running without errors
| epoch   2 |   200/ 2983 batches | lr 0.20 | ms/batch 1134.30 | loss  6.37 | ppl   586.28
| epoch   2 |   400/ 2983 batches | lr 0.20 | ms/batch 1122.55 | loss  6.35 | ppl   572.59
| epoch   2 |   600/ 2983 batches | lr 0.20 | ms/batch 1132.00 | loss  6.27 | ppl   527.42
| epoch   2 |   800/ 2983 batches | lr 0.20 | ms/batch 1133.55 | loss  6.30 | ppl   545.54
| epoch   2 |  1000/ 2983 batches | lr 0.20 | ms/batch 1138.15 | loss  6.27 | ppl   530.45
| epoch   2 |  1200/ 2983 batches | lr 0.20 | ms/batch 1132.08 | loss  6.31 | ppl   549.63
| epoch   2 |  1400/ 2983 batches | lr 0.20 | ms/batch 1123.07 | loss  6.29 | ppl   540.23
| epoch   2 |  1600/ 2983 batches | lr 0.20 | ms/batch 1123.65 | loss  6.32 | ppl   557.93
| epoch   2 |  1800/ 2983 batches | lr 0.20 | ms/batch 1135.70 | loss  6.25 | ppl   517.59
| epoch   2 |  2000/ 2983 batches | lr 0.20 | ms/batch 1146.25 | loss  6.29 | ppl   536.96
| epoch   2 |  2200/ 2983 batches | lr 0.20 | ms/batch 1156.97 | loss  6.22 | ppl   504.91
| epoch   2 |  2400/ 2983 batches | lr 0.20 | ms/batch 1132.16 | loss  6.23 | ppl   507.45
| epoch   2 |  2600/ 2983 batches | lr 0.20 | ms/batch 1127.65 | loss  6.25 | ppl   518.76
| epoch   2 |  2800/ 2983 batches | lr 0.20 | ms/batch 1140.47 | loss  6.20 | ppl   494.61
-----------------------------------------------------------------------------------------
| end of epoch   2 | time: 3497.55s | valid loss  2.51 | valid ppl    12.36
-----------------------------------------------------------------------------------------
Running without errors
| epoch   3 |   200/ 2983 batches | lr 0.20 | ms/batch 1130.98 | loss  6.19 | ppl   489.85
| epoch   3 |   400/ 2983 batches | lr 0.20 | ms/batch 1129.42 | loss  6.18 | ppl   482.49
| epoch   3 |   600/ 2983 batches | lr 0.20 | ms/batch 1125.90 | loss  6.08 | ppl   438.60
| epoch   3 |   800/ 2983 batches | lr 0.20 | ms/batch 1125.97 | loss  6.15 | ppl   467.06
| epoch   3 |  1000/ 2983 batches | lr 0.20 | ms/batch 1142.98 | loss  6.11 | ppl   450.03
| epoch   3 |  1200/ 2983 batches | lr 0.20 | ms/batch 1135.57 | loss  6.14 | ppl   465.77
| epoch   3 |  1400/ 2983 batches | lr 0.20 | ms/batch 1132.83 | loss  6.14 | ppl   463.00
| epoch   3 |  1600/ 2983 batches | lr 0.20 | ms/batch 1123.92 | loss  6.18 | ppl   481.44
| epoch   3 |  1800/ 2983 batches | lr 0.20 | ms/batch 1129.61 | loss  6.10 | ppl   444.44
| epoch   3 |  2000/ 2983 batches | lr 0.20 | ms/batch 1156.01 | loss  6.14 | ppl   464.53
| epoch   3 |  2200/ 2983 batches | lr 0.20 | ms/batch 1126.82 | loss  6.11 | ppl   452.29
| epoch   3 |  2400/ 2983 batches | lr 0.20 | ms/batch 1123.01 | loss  6.11 | ppl   448.33
| epoch   3 |  2600/ 2983 batches | lr 0.20 | ms/batch 1129.16 | loss  6.12 | ppl   454.97
| epoch   3 |  2800/ 2983 batches | lr 0.20 | ms/batch 1144.60 | loss  6.07 | ppl   433.89
-----------------------------------------------------------------------------------------
| end of epoch   3 | time: 3486.39s | valid loss  2.47 | valid ppl    11.84
-----------------------------------------------------------------------------------------
Running without errors
| epoch   4 |   200/ 2983 batches | lr 0.20 | ms/batch 1126.10 | loss  6.10 | ppl   448.01
| epoch   4 |   400/ 2983 batches | lr 0.20 | ms/batch 1119.23 | loss  6.09 | ppl   441.30
| epoch   4 |   600/ 2983 batches | lr 0.20 | ms/batch 1136.32 | loss  6.02 | ppl   412.00
| epoch   4 |   800/ 2983 batches | lr 0.20 | ms/batch 1115.50 | loss  6.09 | ppl   439.28
| epoch   4 |  1000/ 2983 batches | lr 0.20 | ms/batch 1122.10 | loss  6.03 | ppl   417.55
| epoch   4 |  1200/ 2983 batches | lr 0.20 | ms/batch 1121.26 | loss  6.06 | ppl   429.84
| epoch   4 |  1400/ 2983 batches | lr 0.20 | ms/batch 1123.70 | loss  6.06 | ppl   427.47
| epoch   4 |  1600/ 2983 batches | lr 0.20 | ms/batch 1136.94 | loss  6.11 | ppl   451.23
| epoch   4 |  1800/ 2983 batches | lr 0.20 | ms/batch 1124.47 | loss  6.02 | ppl   413.05
| epoch   4 |  2000/ 2983 batches | lr 0.20 | ms/batch 1127.31 | loss  6.07 | ppl   431.41
| epoch   4 |  2200/ 2983 batches | lr 0.20 | ms/batch 1171.04 | loss  5.99 | ppl   399.13
| epoch   4 |  2400/ 2983 batches | lr 0.20 | ms/batch 1155.84 | loss  6.00 | ppl   403.44
| epoch   4 |  2600/ 2983 batches | lr 0.20 | ms/batch 1139.46 | loss  6.02 | ppl   411.17
| epoch   4 |  2800/ 2983 batches | lr 0.20 | ms/batch 1144.21 | loss  5.98 | ppl   394.14
-----------------------------------------------------------------------------------------
| end of epoch   4 | time: 3496.50s | valid loss  2.44 | valid ppl    11.43
-----------------------------------------------------------------------------------------
Running without errors
| epoch   5 |   200/ 2983 batches | lr 0.20 | ms/batch 1163.82 | loss  5.99 | ppl   398.89
| epoch   5 |   400/ 2983 batches | lr 0.20 | ms/batch 1164.48 | loss  5.98 | ppl   395.59
| epoch   5 |   600/ 2983 batches | lr 0.20 | ms/batch 1162.38 | loss  5.89 | ppl   363.09
| epoch   5 |   800/ 2983 batches | lr 0.20 | ms/batch 1138.64 | loss  5.96 | ppl   387.54
| epoch   5 |  1000/ 2983 batches | lr 0.20 | ms/batch 1115.35 | loss  5.95 | ppl   384.63
| epoch   5 |  1200/ 2983 batches | lr 0.20 | ms/batch 1154.24 | loss  5.99 | ppl   399.15
| epoch   5 |  1400/ 2983 batches | lr 0.20 | ms/batch 1145.11 | loss  5.99 | ppl   400.44
| epoch   5 |  1600/ 2983 batches | lr 0.20 | ms/batch 1152.10 | loss  6.03 | ppl   414.32
| epoch   5 |  1800/ 2983 batches | lr 0.20 | ms/batch 1152.35 | loss  5.93 | ppl   375.35
| epoch   5 |  2000/ 2983 batches | lr 0.20 | ms/batch 1147.98 | loss  5.98 | ppl   396.36
| epoch   5 |  2200/ 2983 batches | lr 0.20 | ms/batch 1155.81 | loss  5.89 | ppl   360.64
| epoch   5 |  2400/ 2983 batches | lr 0.20 | ms/batch 1143.06 | loss  5.91 | ppl   368.70
| epoch   5 |  2600/ 2983 batches | lr 0.20 | ms/batch 1147.19 | loss  5.94 | ppl   380.87
| epoch   5 |  2800/ 2983 batches | lr 0.20 | ms/batch 1144.55 | loss  5.89 | ppl   362.39
-----------------------------------------------------------------------------------------
| end of epoch   5 | time: 3542.77s | valid loss  2.42 | valid ppl    11.24
-----------------------------------------------------------------------------------------
Running without errors
| epoch   6 |   200/ 2983 batches | lr 0.20 | ms/batch 1152.66 | loss  5.90 | ppl   366.29
| epoch   6 |   400/ 2983 batches | lr 0.20 | ms/batch 1141.86 | loss  5.91 | ppl   368.71
| epoch   6 |   600/ 2983 batches | lr 0.20 | ms/batch 1143.62 | loss  5.79 | ppl   327.17
| epoch   6 |   800/ 2983 batches | lr 0.20 | ms/batch 1141.81 | loss  5.86 | ppl   349.23
| epoch   6 |  1000/ 2983 batches | lr 0.20 | ms/batch 1147.30 | loss  5.81 | ppl   333.37
| epoch   6 |  1200/ 2983 batches | lr 0.20 | ms/batch 1161.49 | loss  5.85 | ppl   347.52
| epoch   6 |  1400/ 2983 batches | lr 0.20 | ms/batch 1171.26 | loss  5.85 | ppl   345.64
| epoch   6 |  1600/ 2983 batches | lr 0.20 | ms/batch 1132.97 | loss  5.88 | ppl   357.87
| epoch   6 |  1800/ 2983 batches | lr 0.20 | ms/batch 1139.80 | loss  5.82 | ppl   335.33
| epoch   6 |  2000/ 2983 batches | lr 0.20 | ms/batch 1167.32 | loss  5.85 | ppl   347.88
| epoch   6 |  2200/ 2983 batches | lr 0.20 | ms/batch 1145.32 | loss  5.77 | ppl   321.11
| epoch   6 |  2400/ 2983 batches | lr 0.20 | ms/batch 1138.39 | loss  5.80 | ppl   331.30
| epoch   6 |  2600/ 2983 batches | lr 0.20 | ms/batch 1167.70 | loss  5.82 | ppl   336.51
| epoch   6 |  2800/ 2983 batches | lr 0.20 | ms/batch 1142.01 | loss  5.80 | ppl   330.00
-----------------------------------------------------------------------------------------
| end of epoch   6 | time: 3545.41s | valid loss  2.40 | valid ppl    11.05
-----------------------------------------------------------------------------------------
Running without errors
| epoch   7 |   200/ 2983 batches | lr 0.20 | ms/batch 1145.98 | loss  5.82 | ppl   338.49
| epoch   7 |   400/ 2983 batches | lr 0.20 | ms/batch 1141.42 | loss  5.82 | ppl   336.16
| epoch   7 |   600/ 2983 batches | lr 0.20 | ms/batch 1155.85 | loss  5.73 | ppl   308.45
| epoch   7 |   800/ 2983 batches | lr 0.20 | ms/batch 1135.27 | loss  5.81 | ppl   334.82
| epoch   7 |  1000/ 2983 batches | lr 0.20 | ms/batch 1147.27 | loss  5.78 | ppl   323.09
| epoch   7 |  1200/ 2983 batches | lr 0.20 | ms/batch 1157.92 | loss  5.80 | ppl   331.45
| epoch   7 |  1400/ 2983 batches | lr 0.20 | ms/batch 1143.45 | loss  5.80 | ppl   331.70
| epoch   7 |  1600/ 2983 batches | lr 0.20 | ms/batch 1175.74 | loss  5.85 | ppl   346.16
| epoch   7 |  1800/ 2983 batches | lr 0.20 | ms/batch 1145.19 | loss  5.77 | ppl   320.84
| epoch   7 |  2000/ 2983 batches | lr 0.20 | ms/batch 1147.07 | loss  5.82 | ppl   335.46
| epoch   7 |  2200/ 2983 batches | lr 0.20 | ms/batch 1151.35 | loss  5.73 | ppl   306.65
| epoch   7 |  2400/ 2983 batches | lr 0.20 | ms/batch 1143.29 | loss  5.75 | ppl   312.64
| epoch   7 |  2600/ 2983 batches | lr 0.20 | ms/batch 1147.43 | loss  5.77 | ppl   320.32
| epoch   7 |  2800/ 2983 batches | lr 0.20 | ms/batch 1145.91 | loss  5.72 | ppl   304.59
-----------------------------------------------------------------------------------------
| end of epoch   7 | time: 3542.28s | valid loss  2.39 | valid ppl    10.92
-----------------------------------------------------------------------------------------
Running without errors
| epoch   8 |   200/ 2983 batches | lr 0.20 | ms/batch 1150.62 | loss  5.76 | ppl   315.78
| epoch   8 |   400/ 2983 batches | lr 0.20 | ms/batch 1145.07 | loss  5.73 | ppl   308.92
| epoch   8 |   600/ 2983 batches | lr 0.20 | ms/batch 1156.80 | loss  5.62 | ppl   275.54
| epoch   8 |   800/ 2983 batches | lr 0.20 | ms/batch 1150.72 | loss  5.69 | ppl   295.42
| epoch   8 |  1000/ 2983 batches | lr 0.20 | ms/batch 1150.33 | loss  5.65 | ppl   283.38
| epoch   8 |  1200/ 2983 batches | lr 0.20 | ms/batch 1163.67 | loss  5.69 | ppl   296.91
| epoch   8 |  1400/ 2983 batches | lr 0.20 | ms/batch 1144.85 | loss  5.70 | ppl   298.35
| epoch   8 |  1600/ 2983 batches | lr 0.20 | ms/batch 1156.91 | loss  5.74 | ppl   311.62
| epoch   8 |  1800/ 2983 batches | lr 0.20 | ms/batch 1150.68 | loss  5.68 | ppl   291.85
Traceback (most recent call last):
  File "main.py", line 211, in <module>
    train(train_data=train_data)
  File "main.py", line 170, in train
    output, aux_loss = model(src=None, trg=data, src_mask=None, trg_mask=trg_mask, is_lm=True)
  File "/jmain01/home/JAD029/jph13/axb14-jph13/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/jmain01/home/JAD029/jph13/axb14-jph13/mog/mog_transformer/playground/Models.py", line 67, in forward
    d_output, aux_loss = self.decoder(trg, e_outputs, src_mask, trg_mask, is_lm, train=train)
  File "/jmain01/home/JAD029/jph13/axb14-jph13/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/jmain01/home/JAD029/jph13/axb14-jph13/mog/mog_transformer/playground/Models.py", line 48, in forward
    x, additional_loss = self.layers[i](x, e_outputs, src_mask, trg_mask, is_lm, train=train)
  File "/jmain01/home/JAD029/jph13/axb14-jph13/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/jmain01/home/JAD029/jph13/axb14-jph13/mog/mog_transformer/playground/Layers.py", line 60, in forward
    attn_out, additional_loss = self.attn_1(x2, x2, x2, mask=trg_mask, train=train)
  File "/jmain01/home/JAD029/jph13/axb14-jph13/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/jmain01/home/JAD029/jph13/axb14-jph13/mog/mog_transformer/playground/moe_attention.py", line 160, in forward
    dispatcher = SparseDispatcher(self.num_experts, gates)
  File "/jmain01/home/JAD029/jph13/axb14-jph13/mog/mog_transformer/playground/moe_attention.py", line 27, in dispatch
    queries_exp = torch.split(query_exp, self._part_sizes, dim=0)
  File "/jmain01/home/JAD029/jph13/axb14-jph13/miniconda3/lib/python3.7/site-packages/torch/functional.py", line 77, in split
    return tensor.split(split_size_or_sections, dim)
  File "/jmain01/home/JAD029/jph13/axb14-jph13/miniconda3/lib/python3.7/site-packages/torch/tensor.py", line 377, in split
    return super(Tensor, self).split_with_sizes(split_size, dim)
RuntimeError: split_with_sizes expects split_sizes to sum exactly to 40 (input tensor's size at dimension 0), but got split_sizes=[0, 0, 0, 0]
srun: error: dgj110: task 0: Exited with exit code 1
